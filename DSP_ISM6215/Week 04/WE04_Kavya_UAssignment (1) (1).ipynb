{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c446558f",
   "metadata": {},
   "source": [
    "##  Assignment on Universal Bank - Kavya Reddy Basupalli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab2ece",
   "metadata": {},
   "source": [
    "### 1.Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8b75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b262d7",
   "metadata": {},
   "source": [
    "### 2. Load the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b49ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Kavya Reddy Basupall/Downloads/UniversalBank (1).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85206a4b",
   "metadata": {},
   "source": [
    "### 3. Explore the Data (Pre-processing of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1743892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80effc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>92697</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>92037</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>63</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>93023</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>90034</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>92612</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  \\\n",
       "4995  4996   29           3      40     92697       1    1.9          3   \n",
       "4996  4997   30           4      15     92037       4    0.4          1   \n",
       "4997  4998   63          39      24     93023       2    0.3          3   \n",
       "4998  4999   65          40      49     90034       3    0.5          2   \n",
       "4999  5000   28           4      83     92612       3    0.8          1   \n",
       "\n",
       "      Mortgage  Personal Loan  Securities Account  CD Account  Online  \\\n",
       "4995         0              0                   0           0       1   \n",
       "4996        85              0                   0           0       1   \n",
       "4997         0              0                   0           0       0   \n",
       "4998         0              0                   0           0       1   \n",
       "4999         0              0                   0           0       1   \n",
       "\n",
       "      CreditCard  \n",
       "4995           0  \n",
       "4996           0  \n",
       "4997           0  \n",
       "4998           0  \n",
       "4999           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16d2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fcb8f",
   "metadata": {},
   "source": [
    "##### There are no categorical variables in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df586ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2500.500000</td>\n",
       "      <td>45.338400</td>\n",
       "      <td>20.104600</td>\n",
       "      <td>73.774200</td>\n",
       "      <td>93152.503000</td>\n",
       "      <td>2.396400</td>\n",
       "      <td>1.937938</td>\n",
       "      <td>1.881000</td>\n",
       "      <td>56.498800</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.06040</td>\n",
       "      <td>0.596800</td>\n",
       "      <td>0.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1443.520003</td>\n",
       "      <td>11.463166</td>\n",
       "      <td>11.467954</td>\n",
       "      <td>46.033729</td>\n",
       "      <td>2121.852197</td>\n",
       "      <td>1.147663</td>\n",
       "      <td>1.747659</td>\n",
       "      <td>0.839869</td>\n",
       "      <td>101.713802</td>\n",
       "      <td>0.294621</td>\n",
       "      <td>0.305809</td>\n",
       "      <td>0.23825</td>\n",
       "      <td>0.490589</td>\n",
       "      <td>0.455637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9307.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1250.750000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>91911.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2500.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>93437.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3750.250000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>94608.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>96651.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID          Age   Experience       Income      ZIP Code  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000   5000.000000   \n",
       "mean   2500.500000    45.338400    20.104600    73.774200  93152.503000   \n",
       "std    1443.520003    11.463166    11.467954    46.033729   2121.852197   \n",
       "min       1.000000    23.000000    -3.000000     8.000000   9307.000000   \n",
       "25%    1250.750000    35.000000    10.000000    39.000000  91911.000000   \n",
       "50%    2500.500000    45.000000    20.000000    64.000000  93437.000000   \n",
       "75%    3750.250000    55.000000    30.000000    98.000000  94608.000000   \n",
       "max    5000.000000    67.000000    43.000000   224.000000  96651.000000   \n",
       "\n",
       "            Family        CCAvg    Education     Mortgage  Personal Loan  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000    5000.000000   \n",
       "mean      2.396400     1.937938     1.881000    56.498800       0.096000   \n",
       "std       1.147663     1.747659     0.839869   101.713802       0.294621   \n",
       "min       1.000000     0.000000     1.000000     0.000000       0.000000   \n",
       "25%       1.000000     0.700000     1.000000     0.000000       0.000000   \n",
       "50%       2.000000     1.500000     2.000000     0.000000       0.000000   \n",
       "75%       3.000000     2.500000     3.000000   101.000000       0.000000   \n",
       "max       4.000000    10.000000     3.000000   635.000000       1.000000   \n",
       "\n",
       "       Securities Account  CD Account       Online   CreditCard  \n",
       "count         5000.000000  5000.00000  5000.000000  5000.000000  \n",
       "mean             0.104400     0.06040     0.596800     0.294000  \n",
       "std              0.305809     0.23825     0.490589     0.455637  \n",
       "min              0.000000     0.00000     0.000000     0.000000  \n",
       "25%              0.000000     0.00000     0.000000     0.000000  \n",
       "50%              0.000000     0.00000     1.000000     0.000000  \n",
       "75%              0.000000     0.00000     1.000000     1.000000  \n",
       "max              1.000000     1.00000     1.000000     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef351d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    0\n",
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "ZIP Code              0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "CreditCard            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a5b69",
   "metadata": {},
   "source": [
    "##### There are no missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec61cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [s.strip() for s in df.columns] \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03e99fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>63</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Experience  Income  Family  CCAvg  Education  Mortgage  \\\n",
       "0      25           1      49       4    1.6          1         0   \n",
       "1      45          19      34       3    1.5          1         0   \n",
       "2      39          15      11       1    1.0          1         0   \n",
       "3      35           9     100       1    2.7          2         0   \n",
       "4      35           8      45       4    1.0          2         0   \n",
       "...   ...         ...     ...     ...    ...        ...       ...   \n",
       "4995   29           3      40       1    1.9          3         0   \n",
       "4996   30           4      15       4    0.4          1        85   \n",
       "4997   63          39      24       2    0.3          3         0   \n",
       "4998   65          40      49       3    0.5          2         0   \n",
       "4999   28           4      83       3    0.8          1         0   \n",
       "\n",
       "      Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0                 0                   1           0       0           0  \n",
       "1                 0                   1           0       0           0  \n",
       "2                 0                   0           0       0           0  \n",
       "3                 0                   0           0       0           0  \n",
       "4                 0                   0           0       0           1  \n",
       "...             ...                 ...         ...     ...         ...  \n",
       "4995              0                   0           0       1           0  \n",
       "4996              0                   0           0       1           0  \n",
       "4997              0                   0           0       0           0  \n",
       "4998              0                   0           0       1           0  \n",
       "4999              0                   0           0       1           1  \n",
       "\n",
       "[5000 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['ID', 'ZIP Code'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd6c88",
   "metadata": {},
   "source": [
    "##### We have dropped the unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb797a",
   "metadata": {},
   "source": [
    "### 4. Data Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c9dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=1)\n",
    "target = 'CD Account'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e861f",
   "metadata": {},
   "source": [
    " ##### We have done 70/30 ratio split and to avoid repitition created variables to represent coulumns and next step shows the standardization in order to remove the differences in sacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81e429dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training and test sets\n",
    "X_train = scaler.transform(train_df[predictors]) \n",
    "y_train = train_df[target] \n",
    "\n",
    "X_test = scaler.transform(test_df[predictors])\n",
    "y_test = test_df[target] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef926496",
   "metadata": {},
   "source": [
    "### 5.Applying Models to the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d4aec",
   "metadata": {},
   "source": [
    "##### Before that creating a dataframe to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2084327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dec713",
   "metadata": {},
   "source": [
    "#### 5.1 Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e002ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none', max_iter=900)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0ad43c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  Accuracy  Precision   Recall       F1\n",
       "0  default logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix_1 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_1[1][1]\n",
    "TN = c_matrix_1[0][0]\n",
    "FP = c_matrix_1[0][1]\n",
    "FN = c_matrix_1[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf192ec",
   "metadata": {},
   "source": [
    "####  5.1.2 Change to liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4828115",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_liblin_model = LogisticRegression(solver='liblinear').fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c50ef370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision   Recall       F1\n",
       "0    default logistic     0.978        1.0  0.60241  0.75188\n",
       "0  liblinear logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_liblin_model.predict(X_test)\n",
    "c_matrix_2 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_2[1][1]\n",
    "TN = c_matrix_2[0][0]\n",
    "FP = c_matrix_2[0][1]\n",
    "FN = c_matrix_2[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"liblinear logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d8ed7",
   "metadata": {},
   "source": [
    "#### 5.1.3 L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "946a7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L2_model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "_ = log_reg_L2_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f161de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6024096385542169"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds_3 = log_reg_L2_model.predict(X_test)\n",
    "c_matrix_3 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_3[1][1]\n",
    "TN = c_matrix_3[0][0]\n",
    "FP = c_matrix_3[0][1]\n",
    "FN = c_matrix_3[1][0]\n",
    "#performance = pd.concat([performance, pd.DataFrame({'model':\"L2 logistic\", \n",
    "                                                    #'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    #'Precision': [TP/(TP+FP)], \n",
    "                                                    #'Recall': [TP/(TP+FN)], \n",
    "                                                    #'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     #}, index=[0])])\n",
    "#performance\n",
    "recall_3 = recall_score(y_test, model_preds_3)\n",
    "recall_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c21c85",
   "metadata": {},
   "source": [
    "#### 5.1.4 L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0513f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L1_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "_ = log_reg_L1_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd0b30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision   Recall       F1\n",
       "0    default logistic     0.978        1.0  0.60241  0.75188\n",
       "0  liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0         L1 logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_L1_model.predict(X_test)\n",
    "c_matrix_4 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_4[1][1]\n",
    "TN = c_matrix_4[0][0]\n",
    "FP = c_matrix_4[0][1]\n",
    "FN = c_matrix_4[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L1 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa3873",
   "metadata": {},
   "source": [
    "#### 5.1.5 Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31ca9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_elastic_model = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5, max_iter=1000)\n",
    "_ = log_reg_elastic_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9dd11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = log_reg_elastic_model.predict(X_test)\n",
    "c_matrix_5 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_5[1][1]\n",
    "TN = c_matrix_5[0][0]\n",
    "FP = c_matrix_5[0][1]\n",
    "FN = c_matrix_5[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Elestic logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af848a6e",
   "metadata": {},
   "source": [
    "#### 5.1.6 Summary for logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7b0fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision   Recall       F1\n",
       "0    default logistic     0.978        1.0  0.60241  0.75188\n",
       "0  liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0         L1 logistic     0.978        1.0  0.60241  0.75188\n",
       "0    Elestic logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44711ff",
   "metadata": {},
   "source": [
    "#### 5.1.7 Logistic Regression using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "479b4cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.6708245243128964\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 529, 'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "920 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "325 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "295 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.         0.66627907        nan        nan        nan 0.\n",
      " 0.66627907 0.66627907 0.25095137 0.66627907 0.25095137 0.67082452\n",
      "        nan        nan 0.                nan 0.                nan\n",
      "        nan        nan 0.66627907        nan        nan        nan\n",
      " 0.25095137 0.25095137 0.66627907        nan 0.66627907 0.66627907\n",
      "        nan        nan        nan 0.66627907 0.                nan\n",
      " 0.                nan        nan        nan        nan        nan\n",
      "        nan 0.         0.66627907 0.                nan 0.66627907\n",
      " 0.66627907        nan 0.66627907 0.25095137 0.         0.66627907\n",
      "        nan 0.67082452 0.66627907        nan        nan 0.\n",
      " 0.67082452 0.         0.         0.66627907 0.66627907 0.25095137\n",
      "        nan 0.66627907        nan 0.25095137 0.66627907 0.\n",
      " 0.66627907        nan 0.         0.66627907        nan 0.\n",
      " 0.                nan        nan        nan 0.67082452        nan\n",
      " 0.66627907 0.66627907        nan 0.67082452        nan 0.66627907\n",
      " 0.66627907 0.         0.         0.66627907        nan        nan\n",
      "        nan        nan 0.66627907        nan        nan        nan\n",
      "        nan 0.66627907 0.25095137 0.         0.66627907 0.\n",
      " 0.66627907 0.66627907 0.                nan        nan        nan\n",
      " 0.66627907        nan 0.66627907        nan        nan 0.66627907\n",
      " 0.         0.25095137 0.         0.                nan 0.66627907\n",
      "        nan 0.66627907 0.66627907 0.66627907 0.66627907 0.66627907\n",
      "        nan 0.66627907 0.66627907 0.         0.         0.66627907\n",
      " 0.66627907 0.66627907        nan        nan 0.66627907 0.66627907\n",
      " 0.         0.         0.66627907        nan        nan 0.25095137\n",
      " 0.         0.66627907        nan        nan 0.66627907        nan\n",
      "        nan 0.66627907 0.66627907 0.66627907        nan 0.66627907\n",
      "        nan 0.         0.66627907 0.66627907        nan 0.66627907\n",
      " 0.66627907        nan 0.25095137 0.25095137        nan 0.\n",
      " 0.66627907        nan 0.66627907 0.                nan        nan\n",
      " 0.66627907 0.66627907        nan        nan 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907        nan 0.67082452 0.         0.66627907\n",
      "        nan 0.                nan 0.                nan 0.66627907\n",
      " 0.         0.         0.66627907 0.25095137 0.66627907 0.\n",
      "        nan        nan        nan        nan        nan 0.\n",
      "        nan        nan        nan 0.         0.66627907 0.66627907\n",
      " 0.                nan 0.         0.66627907        nan 0.25095137\n",
      " 0.66627907        nan        nan 0.66627907        nan 0.66627907\n",
      " 0.66627907 0.         0.66627907        nan 0.66627907 0.\n",
      "        nan        nan 0.66627907        nan 0.         0.\n",
      "        nan 0.66627907 0.66627907 0.66627907 0.66627907        nan\n",
      " 0.66627907        nan 0.                nan 0.67082452 0.66627907\n",
      " 0.66627907        nan 0.66627907 0.66627907 0.66627907 0.\n",
      " 0.66627907 0.67082452        nan 0.25095137        nan        nan\n",
      " 0.         0.66627907 0.66627907 0.66627907 0.66627907 0.\n",
      " 0.         0.66627907 0.66627907 0.66627907 0.66627907 0.25095137\n",
      " 0.66627907 0.66627907 0.66627907 0.25095137 0.66627907 0.66627907\n",
      " 0.                nan        nan 0.25095137 0.         0.\n",
      "        nan        nan 0.66627907        nan 0.                nan\n",
      " 0.         0.66627907 0.25095137 0.         0.66627907 0.66627907\n",
      "        nan        nan 0.66627907        nan 0.66627907 0.66627907\n",
      "        nan 0.66627907        nan 0.                nan 0.\n",
      " 0.25095137 0.67082452 0.67082452 0.66627907        nan 0.66627907\n",
      " 0.67082452 0.         0.66627907        nan 0.67082452        nan\n",
      " 0.66627907 0.66627907        nan 0.         0.66627907 0.\n",
      " 0.66627907        nan 0.25095137        nan        nan 0.\n",
      " 0.66627907        nan        nan        nan 0.66627907        nan\n",
      "        nan 0.67082452 0.66627907 0.66627907        nan        nan\n",
      " 0.                nan        nan        nan 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.66627907        nan\n",
      "        nan 0.66627907        nan        nan 0.         0.67082452\n",
      " 0.66627907 0.66627907        nan 0.                nan 0.66627907\n",
      " 0.         0.66627907 0.66627907        nan        nan 0.66627907\n",
      " 0.25095137 0.66627907 0.66627907 0.66627907        nan 0.66627907\n",
      " 0.66627907 0.25095137        nan        nan        nan 0.66627907\n",
      " 0.66627907        nan        nan 0.                nan 0.66627907\n",
      " 0.66627907 0.25095137 0.66627907 0.66627907 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907        nan 0.66627907 0.66627907 0.66627907\n",
      "        nan        nan 0.66627907 0.66627907 0.66627907        nan\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.         0.\n",
      " 0.66627907        nan        nan        nan 0.                nan\n",
      " 0.66627907 0.67082452 0.66627907        nan 0.66627907        nan\n",
      "        nan        nan        nan        nan 0.66627907 0.67082452\n",
      " 0.         0.66627907 0.66627907 0.66627907 0.                nan\n",
      "        nan 0.                nan 0.                nan 0.66627907\n",
      " 0.         0.66627907        nan 0.66627907        nan        nan\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.         0.66627907\n",
      " 0.67082452        nan        nan        nan 0.66627907        nan\n",
      "        nan 0.66627907        nan        nan 0.66627907 0.\n",
      "        nan 0.                nan 0.67082452 0.66627907        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66627907 0.66627907 0.66627907 0.         0.66627907        nan\n",
      " 0.         0.66627907]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {'C':[0.001,0.1,0.001,1,10], # C is the regulization strength\n",
    "               'penalty':['l1', 'l2','elasticnet','none'],\n",
    "              'solver':['saga','liblinear'],\n",
    "              'max_iter': np.arange(500,1000)\n",
    "                  \n",
    "}\n",
    "\n",
    "lg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator =lg, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestlogestic = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9276c819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n",
      "The best recall score is 0.6708245243128964\n",
      "... with parameters: {'C': 0.05, 'max_iter': 229, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength-0.05,min_regulization_strength+0.05), \n",
    "               'penalty':[best_penality],\n",
    "              'solver':[best_solver],\n",
    "              'max_iter': np.arange(min_iter-300,min_iter+300)\n",
    "}\n",
    "\n",
    "lgr =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = lgr, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestlgr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd316afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_lr={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77d63675",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ccd64",
   "metadata": {},
   "source": [
    "### 5.2 Model the data using the SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153356aa",
   "metadata": {},
   "source": [
    "##### Let's create a dataframe to load the SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b43b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_svm = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4104287",
   "metadata": {},
   "source": [
    "#### 5.2.1 Fit a SVM classification model using linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf30d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\")\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f8a6214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  Accuracy  Precision   Recall       F1\n",
       "0  linear svm     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "c_matrix_6 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_6[1][1]\n",
    "TN = c_matrix_6[0][0]\n",
    "FP = c_matrix_6[0][1]\n",
    "FN = c_matrix_6[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"linear svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5d25b",
   "metadata": {},
   "source": [
    "#### 5.2.2 Fit a SVM classification model using rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88e6f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale')\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caad8a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  Accuracy  Precision   Recall        F1\n",
       "0  linear svm  0.978000   1.000000  0.60241  0.751880\n",
       "0     rbf svm  0.974667   0.909091  0.60241  0.724638"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "c_matrix_7 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_7[1][1]\n",
    "TN = c_matrix_7[0][0]\n",
    "FP = c_matrix_7[0][1]\n",
    "FN = c_matrix_7[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"rbf svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599b02d",
   "metadata": {},
   "source": [
    "#### 5.2.3 Fit a SVM classification model using polynomial kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c2ff4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=10)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5132867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  Accuracy  Precision   Recall        F1\n",
       "0  linear svm  0.978000   1.000000  0.60241  0.751880\n",
       "0     rbf svm  0.974667   0.909091  0.60241  0.724638\n",
       "0    poly svm  0.970000   0.806452  0.60241  0.689655"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "c_matrix_8 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_8[1][1]\n",
    "TN = c_matrix_8[0][0]\n",
    "FP = c_matrix_8[0][1]\n",
    "FN = c_matrix_8[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"poly svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1385d61",
   "metadata": {},
   "source": [
    "#### 5.3 Decision Tree Modelling using RandomSearchCV combined with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4db1be",
   "metadata": {},
   "source": [
    "Using the Random search to get the best parameters from the range which can be later used in the Grid search to get more refined results with less overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87fd32d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.7076109936575052\n",
      "... with parameters: {'min_samples_split': 97, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 89, 'max_depth': 19, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.29682875 0.59830867 0.59830867 0.59830867 0.59830867 0.59344609\n",
      " 0.59830867 0.36194503 0.55729387 0.6756871  0.6256871  0.59830867\n",
      " 0.59830867 0.59830867 0.14545455 0.59830867 0.59830867 0.59830867\n",
      " 0.         0.29682875 0.         0.59830867 0.59376321 0.56162791\n",
      " 0.62114165 0.36194503 0.652537   0.59376321 0.59344609 0.54799154\n",
      " 0.29682875 0.64799154 0.552537   0.59830867 0.51638478 0.59830867\n",
      " 0.36194503 0.12272727 0.65285412 0.59830867 0.53890063 0.12272727\n",
      " 0.51638478 0.59830867 0.05       0.63890063 0.59830867 0.59830867\n",
      " 0.58921776 0.14545455 0.59830867 0.59830867 0.59830867 0.56183932\n",
      " 0.59830867 0.59830867 0.14545455 0.14545455 0.50697674 0.36194503\n",
      " 0.12272727 0.63890063 0.05       0.14545455 0.56162791 0.56649049\n",
      " 0.6435518  0.63890063 0.59830867 0.63890063 0.59830867 0.59830867\n",
      " 0.14545455 0.         0.59830867 0.         0.59830867 0.59830867\n",
      " 0.59830867 0.652537   0.67114165 0.62103594 0.59830867 0.36194503\n",
      " 0.56183932 0.36194503 0.         0.36194503 0.64799154 0.36194503\n",
      " 0.59830867 0.59830867 0.59830867 0.59830867 0.         0.4846723\n",
      " 0.29682875 0.70295983 0.59830867        nan 0.19545455 0.56162791\n",
      " 0.36194503 0.59830867 0.36194503        nan 0.         0.57526427\n",
      " 0.67114165 0.59830867 0.05       0.59344609 0.53890063 0.59830867\n",
      " 0.59830867 0.652537   0.59830867 0.59830867 0.         0.59830867\n",
      " 0.19545455 0.56162791 0.652537   0.59830867 0.29682875 0.4846723\n",
      " 0.56162791 0.59830867 0.59830867 0.59830867 0.59830867 0.\n",
      " 0.29682875 0.70295983 0.59830867 0.23773784 0.62114165 0.4846723\n",
      " 0.6845666  0.59830867 0.59830867 0.4846723  0.59830867 0.65708245\n",
      " 0.59830867 0.         0.55718816 0.49788584 0.12272727 0.64799154\n",
      " 0.12272727        nan 0.51638478 0.59830867 0.59830867 0.52061311\n",
      " 0.59830867 0.60295983 0.60750529 0.59830867 0.29682875 0.51638478\n",
      " 0.19545455 0.6845666  0.29682875 0.59830867 0.56162791 0.56183932\n",
      " 0.36194503 0.59830867 0.54799154 0.         0.59841438 0.59830867\n",
      " 0.29682875 0.14545455 0.59830867 0.65750529 0.05       0.59830867\n",
      " 0.5755814  0.59830867 0.59830867 0.59830867 0.59344609 0.12272727\n",
      " 0.29682875 0.59830867 0.59830867 0.59830867 0.29682875 0.59830867\n",
      " 0.59830867 0.59830867 0.59830867 0.         0.59830867 0.65718816\n",
      " 0.14545455 0.64386892 0.23773784 0.59830867 0.29682875 0.12272727\n",
      "        nan 0.05       0.59830867 0.69841438 0.29682875 0.55729387\n",
      " 0.14545455 0.29682875 0.29682875 0.12272727 0.29682875 0.29682875\n",
      " 0.59830867 0.12272727 0.70295983 0.14545455 0.64799154 0.64820296\n",
      " 0.59830867 0.62114165 0.29682875 0.29682875 0.59830867 0.\n",
      " 0.29682875 0.29682875 0.59830867 0.14545455 0.59830867 0.59830867\n",
      " 0.29682875 0.59830867 0.59376321 0.         0.59830867 0.56183932\n",
      " 0.29682875 0.29682875 0.36194503 0.59830867 0.63890063 0.64799154\n",
      " 0.59830867 0.62103594 0.58002114 0.29682875 0.14545455 0.6256871\n",
      " 0.59830867 0.51638478 0.29682875 0.59830867 0.29682875        nan\n",
      " 0.59830867 0.59830867 0.05       0.59830867 0.14545455 0.57547569\n",
      " 0.         0.29682875 0.14545455 0.29682875 0.56162791 0.12272727\n",
      " 0.70295983 0.59830867 0.4846723  0.56162791 0.63890063 0.59830867\n",
      " 0.59830867 0.05       0.60295983 0.64799154 0.70295983 0.56162791\n",
      " 0.52061311 0.36194503 0.59830867 0.59830867 0.69841438 0.29682875\n",
      " 0.51638478 0.14545455 0.59830867 0.65750529 0.12272727 0.59830867\n",
      " 0.65708245 0.64799154 0.59830867 0.14545455 0.12272727 0.59830867\n",
      " 0.36194503 0.652537   0.59830867 0.59830867 0.59830867 0.48879493\n",
      " 0.4846723  0.29682875 0.63890063 0.63890063 0.59344609 0.59830867\n",
      " 0.         0.36194503 0.4846723  0.59830867 0.56183932 0.29682875\n",
      " 0.56162791 0.36194503 0.36194503 0.63890063 0.14545455 0.12272727\n",
      " 0.60708245 0.29682875 0.6256871         nan 0.59830867 0.59830867\n",
      " 0.29682875 0.36194503 0.59344609 0.59830867 0.59376321 0.70295983\n",
      " 0.59830867 0.4846723  0.50697674 0.12272727 0.59830867 0.59830867\n",
      " 0.29682875 0.         0.65285412 0.4846723  0.         0.4846723\n",
      " 0.29682875 0.59830867 0.60295983 0.         0.05       0.05\n",
      " 0.59830867 0.652537   0.29682875 0.59830867 0.         0.36194503\n",
      " 0.59830867 0.14545455 0.29682875 0.         0.         0.59830867\n",
      " 0.59830867 0.63890063 0.59830867 0.56183932 0.59344609 0.59830867\n",
      " 0.59830867 0.         0.66649049 0.59830867 0.59830867 0.64799154\n",
      " 0.12272727 0.70761099 0.59830867 0.4846723  0.6256871  0.14545455\n",
      " 0.59830867 0.59830867 0.         0.05       0.59830867 0.59841438\n",
      " 0.         0.59830867 0.56162791 0.63890063 0.         0.56162791\n",
      " 0.59830867 0.59830867 0.14545455 0.19545455 0.59830867 0.69408034\n",
      " 0.59830867 0.59830867 0.59830867 0.         0.652537   0.59830867\n",
      " 0.05       0.66627907 0.59344609 0.53890063 0.59376321 0.61205074\n",
      " 0.59830867 0.59830867 0.70295983 0.59830867 0.59830867 0.59830867\n",
      " 0.66649049 0.         0.69841438 0.59830867 0.29682875 0.\n",
      " 0.29682875 0.29682875 0.59830867 0.29682875 0.52526427 0.59344609\n",
      " 0.29682875 0.29682875 0.         0.59830867 0.         0.29682875\n",
      " 0.65264271 0.29682875 0.59830867 0.59830867 0.4846723  0.61205074\n",
      " 0.56162791 0.         0.66649049 0.36194503 0.70295983 0.64799154\n",
      " 0.29682875 0.54799154 0.70295983 0.36194503 0.29682875 0.6435518\n",
      " 0.         0.52526427 0.         0.51638478 0.59830867 0.4846723\n",
      " 0.53890063 0.59830867 0.59830867 0.59344609 0.59830867 0.29682875\n",
      " 0.59830867 0.49788584 0.652537   0.65750529 0.29682875 0.68002114\n",
      " 0.23773784 0.29682875 0.652537   0.6435518  0.65708245 0.\n",
      " 0.56183932 0.59376321 0.64799154 0.58921776 0.59830867 0.14545455\n",
      " 0.05       0.36194503 0.4846723  0.57526427 0.         0.59830867\n",
      " 0.55729387 0.05       0.64799154 0.14545455 0.36194503 0.29682875\n",
      " 0.29682875 0.63890063]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kavya Reddy Basupall\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.33905844 0.59818182 0.59818182 0.59818182 0.59818182 0.62438961\n",
      " 0.59818182 0.39246753 0.53538312 0.71803247 0.67003896 0.59818182\n",
      " 0.59818182 0.59818182 0.15542857 0.59818182 0.59818182 0.59818182\n",
      " 0.         0.33905844 0.         0.59818182 0.58675325 0.6061039\n",
      " 0.65861039 0.39246753 0.64267532 0.58675325 0.62438961 0.56038961\n",
      " 0.33905844 0.65524675 0.57067532 0.59818182 0.49424026 0.59818182\n",
      " 0.39246753 0.15314286 0.64949351 0.59818182 0.55924675 0.15314286\n",
      " 0.49766883 0.59818182 0.072      0.63924675 0.59818182 0.59818182\n",
      " 0.61866883 0.15542857 0.59818182 0.59818182 0.59818182 0.54681169\n",
      " 0.59818182 0.59818182 0.15542857 0.15542857 0.50338961 0.39246753\n",
      " 0.15314286 0.63924675 0.072      0.15542857 0.6061039  0.57181169\n",
      " 0.64951299 0.64838961 0.59818182 0.63924675 0.59818182 0.59818182\n",
      " 0.15542857 0.         0.59818182 0.         0.59818182 0.59818182\n",
      " 0.59818182 0.65067532 0.65751299 0.63695455 0.59818182 0.39246753\n",
      " 0.54566883 0.39246753 0.         0.39246753 0.66206494 0.39246753\n",
      " 0.59818182 0.59818182 0.59818182 0.59818182 0.         0.49646753\n",
      " 0.33905844 0.70318182 0.59818182        nan 0.21942857 0.6061039\n",
      " 0.39246753 0.59818182 0.39246753        nan 0.         0.61753247\n",
      " 0.74774675 0.59818182 0.072      0.62438961 0.55924675 0.59818182\n",
      " 0.59818182 0.64267532 0.59818182 0.59818182 0.         0.59818182\n",
      " 0.21942857 0.6061039  0.64267532 0.59818182 0.33905844 0.49646753\n",
      " 0.6061039  0.59818182 0.59818182 0.59818182 0.59818182 0.\n",
      " 0.33905844 0.70318182 0.59818182 0.27391558 0.65861039 0.49646753\n",
      " 0.70662987 0.59818182 0.59818182 0.49646753 0.59818182 0.66438961\n",
      " 0.59818182 0.         0.5729026  0.4931039  0.15314286 0.65524675\n",
      " 0.15314286        nan 0.49424026 0.59818182 0.59818182 0.51253247\n",
      " 0.59818182 0.62318182 0.63575325 0.59818182 0.33905844 0.49424026\n",
      " 0.21942857 0.8322013  0.33905844 0.59818182 0.6061039  0.54566883\n",
      " 0.39246753 0.59818182 0.58324675 0.         0.62546753 0.59818182\n",
      " 0.33905844 0.15542857 0.59818182 0.68832468 0.072      0.59818182\n",
      " 0.59581169 0.59818182 0.59818182 0.59818182 0.62438961 0.13828571\n",
      " 0.33905844 0.59818182 0.59818182 0.59818182 0.33905844 0.59818182\n",
      " 0.59818182 0.59818182 0.59818182 0.         0.59818182 0.66892208\n",
      " 0.15542857 0.66661039 0.27391558 0.59818182 0.33905844 0.15314286\n",
      "        nan 0.072      0.59818182 0.69175325 0.33905844 0.53538312\n",
      " 0.15542857 0.33905844 0.33905844 0.15314286 0.33905844 0.33905844\n",
      " 0.59818182 0.15314286 0.70318182 0.15542857 0.65524675 0.65292857\n",
      " 0.59818182 0.65861039 0.33905844 0.33905844 0.59818182 0.\n",
      " 0.33905844 0.33905844 0.59818182 0.15542857 0.59818182 0.59818182\n",
      " 0.33905844 0.59818182 0.58675325 0.         0.59818182 0.54566883\n",
      " 0.33905844 0.33905844 0.39246753 0.59818182 0.63924675 0.65524675\n",
      " 0.59818182 0.63695455 0.56624026 0.33905844 0.15542857 0.67003896\n",
      " 0.59818182 0.49424026 0.33905844 0.59818182 0.33905844        nan\n",
      " 0.59818182 0.59818182 0.072      0.59818182 0.15542857 0.55595455\n",
      " 0.         0.33905844 0.15542857 0.33905844 0.6061039  0.15314286\n",
      " 0.70318182 0.59818182 0.49646753 0.6061039  0.63924675 0.59818182\n",
      " 0.59818182 0.072      0.62318182 0.66206494 0.70318182 0.6061039\n",
      " 0.51253247 0.39246753 0.59818182 0.59818182 0.69175325 0.33905844\n",
      " 0.49538312 0.15542857 0.59818182 0.68832468 0.15314286 0.59818182\n",
      " 0.66324675 0.66206494 0.59818182 0.15542857 0.15314286 0.59818182\n",
      " 0.39246753 0.65067532 0.59818182 0.59818182 0.59818182 0.4851039\n",
      " 0.49646753 0.33905844 0.63924675 0.63924675 0.62438961 0.59818182\n",
      " 0.         0.39246753 0.49646753 0.59818182 0.54566883 0.33905844\n",
      " 0.6061039  0.39246753 0.39246753 0.63924675 0.15542857 0.15314286\n",
      " 0.63581818 0.33905844 0.67003896        nan 0.59818182 0.59818182\n",
      " 0.33905844 0.39246753 0.62438961 0.59818182 0.58675325 0.70318182\n",
      " 0.59818182 0.49646753 0.50338961 0.15314286 0.59818182 0.59818182\n",
      " 0.33905844 0.         0.64949351 0.49646753 0.         0.49646753\n",
      " 0.33905844 0.59818182 0.62318182 0.         0.072      0.072\n",
      " 0.59818182 0.64267532 0.33905844 0.59818182 0.         0.39246753\n",
      " 0.59818182 0.15542857 0.33905844 0.         0.         0.59818182\n",
      " 0.59818182 0.63924675 0.59818182 0.54566883 0.62438961 0.59818182\n",
      " 0.59818182 0.         0.65181169 0.59818182 0.59818182 0.66434416\n",
      " 0.13828571 0.70545455 0.59818182 0.49646753 0.67003896 0.15542857\n",
      " 0.59818182 0.59818182 0.         0.072      0.59818182 0.61175325\n",
      " 0.         0.59818182 0.6061039  0.63924675 0.         0.6061039\n",
      " 0.59818182 0.59818182 0.15542857 0.21942857 0.59818182 0.73401299\n",
      " 0.59818182 0.59818182 0.59818182 0.         0.65067532 0.59818182\n",
      " 0.072      0.68605844 0.62438961 0.55924675 0.58675325 0.64832468\n",
      " 0.59818182 0.59818182 0.70318182 0.59818182 0.59818182 0.59818182\n",
      " 0.65181169 0.         0.69175325 0.59818182 0.33905844 0.\n",
      " 0.33905844 0.33905844 0.59818182 0.33905844 0.53753247 0.62438961\n",
      " 0.33905844 0.33905844 0.         0.59818182 0.         0.33905844\n",
      " 0.71457143 0.33905844 0.59818182 0.59818182 0.49646753 0.64718182\n",
      " 0.6061039  0.         0.65181169 0.39246753 0.70318182 0.65638961\n",
      " 0.33905844 0.58324675 0.70318182 0.39246753 0.33905844 0.64837013\n",
      " 0.         0.53753247 0.         0.49424026 0.59818182 0.49646753\n",
      " 0.55924675 0.59818182 0.59818182 0.62438961 0.59818182 0.33905844\n",
      " 0.59818182 0.4931039  0.65067532 0.68832468 0.33905844 0.76257792\n",
      " 0.27391558 0.33905844 0.64267532 0.65978571 0.67920779 0.\n",
      " 0.54566883 0.58675325 0.65524675 0.61866883 0.59818182 0.15542857\n",
      " 0.072      0.39246753 0.49646753 0.60953247 0.         0.59818182\n",
      " 0.53538312 0.072      0.66206494 0.15542857 0.39246753 0.33905844\n",
      " 0.33905844 0.63924675]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,25), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c3d32ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is 0.7076109936575052\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 17, 'max_leaf_nodes': 87, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 95}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c88d7641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9686667 Precision=0.7571429 Recall=0.6385542 F1=0.6928105\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac76cf30",
   "metadata": {},
   "source": [
    "###  Conclusion:\n",
    "1.Among all the predictive models so far, It is clear that Decision Tree is the best model as it shows our measuring score recall value more.\n",
    "\n",
    "2.As we clearly observe recall value is same for all logistic regression and SVM Models with a value of 0.60241 this may be due to data imbalance.\n",
    "\n",
    "3.It is clear that using random search and grid search performance with decision trees is better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

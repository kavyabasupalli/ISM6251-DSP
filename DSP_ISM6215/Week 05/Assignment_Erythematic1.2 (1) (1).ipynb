{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2e2b64",
   "metadata": {},
   "source": [
    "## Data Mining  Assignment 1  - Predictive Modelling - Kavya Reddy Basupalli "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45957646",
   "metadata": {},
   "source": [
    "### Understanding Scoring Metric\n",
    "\n",
    "Now that we have prepared our data and pre-processed it,its time for us to understand the business problem in depth and its related scoring metric. According to our business problem, our predictive model tries to find the severity of the Erythemato-squamous diseases in its initial stage.\n",
    "\n",
    "Lets define few metrics,\n",
    "\n",
    "*True Positive= Our model predicts the severity of the disease, but in reality our prediction comes to be true so there is no harm on either end.\n",
    "\n",
    "*False Positive = Our model predicts the severity of the disease, but in reality our prediction comes false so now the money spent for its diagnosis would be considered as loss.\n",
    "\n",
    "*True Negative= Our model predicts no severity of disease, but in reality our prediction is true so there is no loss.\n",
    "\n",
    "*False Negative= Our model predicts no severity of disease, but in reality our prediction is false, in that case human with those symptoms will not get diagnosed and it leads to serious health issues.\n",
    "\n",
    "\n",
    "\n",
    "So I feel False Negative has major impact on human's health and life because it effects them mentally and physically.\n",
    "Now, since False Negative is considered 'Recall' is the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cdc0da",
   "metadata": {},
   "source": [
    "### Step 1:  Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ada7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae81bf",
   "metadata": {},
   "source": [
    "### Step 2 : Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd4ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERYTHEMA</th>\n",
       "      <th>SCALING</th>\n",
       "      <th>DEFINITE_BORDERS</th>\n",
       "      <th>ITCHING</th>\n",
       "      <th>KOEBNER_PHENOMENON</th>\n",
       "      <th>POLYGONAL_PAPULES</th>\n",
       "      <th>FOLLICULAR_PAPULES</th>\n",
       "      <th>ORAL_MUCOSAL_INVOLVEMENT</th>\n",
       "      <th>KNEE_AND_ELBOW_INVOLVEMENT</th>\n",
       "      <th>SCALP_INVOLVEMENT</th>\n",
       "      <th>...</th>\n",
       "      <th>DISAPPEARANCE_OF_THE_GRANULAR_LAYER</th>\n",
       "      <th>VACUOLISATION_AND_DAMAGE_OF_BASAL_LAYER</th>\n",
       "      <th>SPONGIOSIS</th>\n",
       "      <th>SAW-TOOTH_APPEARANCE_OF_RETES</th>\n",
       "      <th>FOLLICULAR_HORN_PLUG</th>\n",
       "      <th>PERIFOLLICULAR_PARAKERATOSIS</th>\n",
       "      <th>INFLAMMATORY_MONOLUCLEAR_INFLITRATE</th>\n",
       "      <th>BAND-LIKE_INFILTRATE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ERYTHEMA  SCALING  DEFINITE_BORDERS  ITCHING  KOEBNER_PHENOMENON  \\\n",
       "0           2        2                 2        0                   0   \n",
       "1           2        2                 1        2                   0   \n",
       "2           2        2                 2        0                   0   \n",
       "3           1        1                 0        1                   1   \n",
       "4           2        3                 2        0                   0   \n",
       "..        ...      ...               ...      ...                 ...   \n",
       "245         3        2                 2        0                   2   \n",
       "246         2        2                 2        0                   1   \n",
       "247         2        2                 2        1                   0   \n",
       "248         2        2                 2        1                   0   \n",
       "249         1        1                 1        0                   0   \n",
       "\n",
       "     POLYGONAL_PAPULES  FOLLICULAR_PAPULES  ORAL_MUCOSAL_INVOLVEMENT  \\\n",
       "0                    0                   0                         0   \n",
       "1                    0                   0                         0   \n",
       "2                    0                   0                         0   \n",
       "3                    0                   0                         0   \n",
       "4                    0                   0                         0   \n",
       "..                 ...                 ...                       ...   \n",
       "245                  0                   0                         0   \n",
       "246                  0                   0                         0   \n",
       "247                  0                   0                         0   \n",
       "248                  0                   2                         0   \n",
       "249                  0                   0                         0   \n",
       "\n",
       "     KNEE_AND_ELBOW_INVOLVEMENT  SCALP_INVOLVEMENT  ...  \\\n",
       "0                             2                  2  ...   \n",
       "1                             0                  0  ...   \n",
       "2                             3                  0  ...   \n",
       "3                             0                  0  ...   \n",
       "4                             3                  2  ...   \n",
       "..                          ...                ...  ...   \n",
       "245                           3                  2  ...   \n",
       "246                           0                  0  ...   \n",
       "247                           0                  0  ...   \n",
       "248                           2                  2  ...   \n",
       "249                           0                  0  ...   \n",
       "\n",
       "     DISAPPEARANCE_OF_THE_GRANULAR_LAYER  \\\n",
       "0                                      3   \n",
       "1                                      0   \n",
       "2                                      2   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "..                                   ...   \n",
       "245                                    0   \n",
       "246                                    0   \n",
       "247                                    0   \n",
       "248                                    0   \n",
       "249                                    0   \n",
       "\n",
       "     VACUOLISATION_AND_DAMAGE_OF_BASAL_LAYER  SPONGIOSIS  \\\n",
       "0                                          0           0   \n",
       "1                                          0           2   \n",
       "2                                          0           0   \n",
       "3                                          0           2   \n",
       "4                                          0           0   \n",
       "..                                       ...         ...   \n",
       "245                                        0           0   \n",
       "246                                        0           2   \n",
       "247                                        0           3   \n",
       "248                                        0           2   \n",
       "249                                        0           2   \n",
       "\n",
       "     SAW-TOOTH_APPEARANCE_OF_RETES  FOLLICULAR_HORN_PLUG  \\\n",
       "0                                0                     0   \n",
       "1                                0                     0   \n",
       "2                                0                     0   \n",
       "3                                0                     0   \n",
       "4                                0                     0   \n",
       "..                             ...                   ...   \n",
       "245                              0                     0   \n",
       "246                              0                     0   \n",
       "247                              0                     0   \n",
       "248                              0                     2   \n",
       "249                              0                     0   \n",
       "\n",
       "     PERIFOLLICULAR_PARAKERATOSIS  INFLAMMATORY_MONOLUCLEAR_INFLITRATE  \\\n",
       "0                               0                                    3   \n",
       "1                               0                                    1   \n",
       "2                               0                                    2   \n",
       "3                               0                                    2   \n",
       "4                               0                                    1   \n",
       "..                            ...                                  ...   \n",
       "245                             0                                    2   \n",
       "246                             0                                    2   \n",
       "247                             0                                    0   \n",
       "248                             2                                    2   \n",
       "249                             0                                    2   \n",
       "\n",
       "     BAND-LIKE_INFILTRATE  AGE  CLASS_CODE  \n",
       "0                       0   36           1  \n",
       "1                       0   33           2  \n",
       "2                       0   23           1  \n",
       "3                       0   60           4  \n",
       "4                       0   70           1  \n",
       "..                    ...  ...         ...  \n",
       "245                     0   60           1  \n",
       "246                     0   22           4  \n",
       "247                     0   33           2  \n",
       "248                     0    7           6  \n",
       "249                     0   62           4  \n",
       "\n",
       "[250 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin= pd.read_csv('C:/Users/Kavya Reddy Basupall/Downloads/disease_train_df.csv')\n",
    "df_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bbfdf",
   "metadata": {},
   "source": [
    "### Step3 : Loading our Previous trained data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70274b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=pd.read_csv('C:/Users/Kavya Reddy Basupall/Downloads/disease_train_X.csv')\n",
    "train_y=pd.read_csv('C:/Users/Kavya Reddy Basupall/Downloads/disease_train_y.csv')\n",
    "test_X=pd.read_csv('C:/Users/Kavya Reddy Basupall/Downloads/disease_test_X.csv')\n",
    "test_y=pd.read_csv('C:/Users/Kavya Reddy Basupall/Downloads/disease_test_y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d48a4",
   "metadata": {},
   "source": [
    "### Step 4: Model the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748beae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5ee2c",
   "metadata": {},
   "source": [
    "### Step 4.1 Logistic Regression using random and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a7dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 494, 'C': 5}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {'C':[0.01,0.1,1,2,5], # C is the regulization strength\n",
    "               'penalty':['l1', 'l2','elasticnet','none'],\n",
    "              'solver':['saga','liblinear'],\n",
    "              'max_iter': np.arange(250,500)\n",
    "                  \n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator =log_reg, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_log_reg = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921dafeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'C': 4.95, 'max_iter': 194, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength-0.05,min_regulization_strength+0.05), \n",
    "               'penalty':[best_penality],\n",
    "              'solver':[best_solver],\n",
    "              'max_iter': np.arange(min_iter-300,min_iter+300)\n",
    "}\n",
    "\n",
    "log_reg =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = log_reg, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_log_reg = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db7cfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=1.0000000 Precision=1.0000000 Recall=1.0000000 F1=1.0000000\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_logistic= {TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48dd6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d9c60",
   "metadata": {},
   "source": [
    "###  Step 4.2 SVM Model using random and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef063ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'kernel': 'rbf', 'gamma': 'scale', 'degree': 4, 'coef0': 8, 'C': 80.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {'C':np.arange(0.1,100,10),  #  regularization parameter.\n",
    "               'kernel':['linear', 'rbf','poly'],\n",
    "              'gamma':['scale','auto'],\n",
    "              'degree':np.arange(1,10), #degree is for the polynomial kernal\n",
    "              'coef0':np.arange(1,10) #coef0 is for the polynomial kernal\n",
    "                  \n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator =svc, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_svc = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b858beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'C': 77.1, 'coef0': 5, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "best_kernel = rand_search.best_params_['kernel']\n",
    "best_gamma = rand_search.best_params_['gamma']\n",
    "min_regulization=rand_search.best_params_['C']\n",
    "best_degree = rand_search.best_params_['degree']\n",
    "best_coef0=rand_search.best_params_['coef0']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization-3,min_regulization+3), \n",
    "               'kernel':[best_kernel],\n",
    "              'gamma':[best_gamma],\n",
    "              'degree': np.arange(best_degree-1,best_degree+1),\n",
    "            'coef0': np.arange(best_coef0-3,best_coef0+3)\n",
    "}\n",
    "\n",
    "svm_grid =  SVC()\n",
    "grid_search = GridSearchCV(estimator = svm_grid, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_svm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533aa1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=1.0000000 Precision=1.0000000 Recall=1.0000000 F1=1.0000000\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_SVM = {TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf94f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm using Random & Grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc117acf",
   "metadata": {},
   "source": [
    "### Step 4.3 Decision Tress using random search and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da9ca663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'min_samples_split': 63, 'min_samples_leaf': 95, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 49, 'max_depth': 3, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,25), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_DTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f54d20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is nan\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 1, 'max_leaf_nodes': 47, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 93, 'min_samples_split': 61}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_DTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "097fd30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=1.0000000 Precision=nan Recall=nan F1=nan\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_Dtree= {TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6a74798",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b4949c",
   "metadata": {},
   "source": [
    "### Step 5: Performance of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01eec164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision  Recall   F1\n",
       "0  logistic using random & grid search       1.0        1.0     1.0  1.0\n",
       "0       svm using Random & Grid search       1.0        1.0     1.0  1.0\n",
       "0                        Decision Tree       1.0        NaN     NaN  NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3621e9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision  Recall   F1\n",
       "0  logistic using random & grid search       1.0        1.0     1.0  1.0\n",
       "0       svm using Random & Grid search       1.0        1.0     1.0  1.0\n",
       "0                        Decision Tree       1.0        NaN     NaN  NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf7380",
   "metadata": {},
   "source": [
    "### Summary \n",
    "1.After fitting varied models to the given data, we interestingly found the scoring metrics to be perfect showing 100% accuracy, precision and recall.\n",
    "\n",
    "2.However, the Decision tree values show NaN.This means this particular model is not the right fit.\n",
    "\n",
    "3.Among the three models, logistic regression and Svm model using random search and grid search showed better performance compared to default modelling technique.\n",
    "\n",
    "4.I have also observed that SVM and logistic regression using random and grid search didn't work for multi classification but when converted it into binary the results were positive completely.\n",
    "\n",
    "5.The Recall Score showed 1.0  which is our desired metric so all of the models have done well interms of performance.\n",
    "\n",
    "Finally,  models perfomed well except the decision trees.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
